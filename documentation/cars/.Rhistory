# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
# Predict on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = log(Price), y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# residuals <- residuals(lm_model$finalModel)
# Extract residuals and fitted values
model_data <- data.frame(
Fitted = fitted(lm_model$finalModel),
Residuals = residuals(lm_model$finalModel)
)
# Converting to dataframe for ggplot
# residuals_df <- data.frame(Residuals = residuals)
# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
geom_histogram(
aes(y = after_stat(density)),
bins = 50,
fill = "steelblue",
color = "white",
alpha = 0.8
) +
geom_density(color = "red", linewidth = 1) +
labs(
title = "Distribution of Model Residuals",
x = "Residuals (Actual - Predicted Price)",
y = "Density"
) +
theme_minimal()
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
labs(
title = "Residuals vs. Fitted Values",
subtitle = "Check for homoscedasticity (constant variance)",
x = "Fitted Values (Predicted Price)",
y = "Residuals (Actual - Predicted)"
) +
theme_minimal()
p1
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
stat_qq(color = "steelblue") +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Normal Q-Q Plot",
subtitle = "Check for normality of residuals",
x = "Theoretical Quantiles",
y = "Sample Quantiles"
) +
theme_minimal()
p2
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/preprocessed/cars_v1.csv", show_col_types = FALSE)
summary(df)
TARGET = 'Price'
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")
EDA_selected = c('Brand_Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)
# Function to winsorize
winsorize <- function(x, limits = c(0.01, 0.99)) {
x[x < quantile(x, limits[1], na.rm = TRUE)] <- quantile(x, limits[1], na.rm = TRUE)
x[x > quantile(x, limits[2], na.rm = TRUE)] <- quantile(x, limits[2], na.rm = TRUE)
x
}
# Apply to new features
selected_data <- selected_data %>%
mutate(across(
all_of(EDA_selected),  # Use all_of() for safety
winsorize
))
# Fixes the random number generator to ensure the same data split every time.
set.seed(123)  # For reproducibility
# Splits the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]
# Option A: Log-transform Price
# Applies the natural logarithm to Price in the training set only (to avoid data leakage).
train_data$log_Price <- log(train_data$Price)
# Option B: Remove extreme values (e.g., top/bottom 1%)
# price_cutoffs <- quantile(train_data$log_Price, c(0.01, 0.99))
# train_clean <- train_data %>%
#   filter(log_Price > price_cutoffs[1] & log_Price < price_cutoffs[2])
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
# Predict on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = log(Price), y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# residuals <- residuals(lm_model$finalModel)
# Extract residuals and fitted values
model_data <- data.frame(
Fitted = fitted(lm_model$finalModel),
Residuals = residuals(lm_model$finalModel)
)
# Converting to dataframe for ggplot
# residuals_df <- data.frame(Residuals = residuals)
# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
geom_histogram(
aes(y = after_stat(density)),
bins = 50,
fill = "steelblue",
color = "white",
alpha = 0.8
) +
geom_density(color = "red", linewidth = 1) +
labs(
title = "Distribution of Model Residuals",
x = "Residuals (Actual - Predicted Price)",
y = "Density"
) +
theme_minimal()
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
labs(
title = "Residuals vs. Fitted Values",
subtitle = "Check for homoscedasticity (constant variance)",
x = "Fitted Values (Predicted Price)",
y = "Residuals (Actual - Predicted)"
) +
theme_minimal()
p1
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
stat_qq(color = "steelblue") +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Normal Q-Q Plot",
subtitle = "Check for normality of residuals",
x = "Theoretical Quantiles",
y = "Sample Quantiles"
) +
theme_minimal()
p2
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/preprocessed/cars_v1.csv", show_col_types = FALSE)
summary(df)
TARGET = 'Price'
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")
EDA_selected = c('Brand_Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)
# Function to winsorize
winsorize <- function(x, limits = c(0.01, 0.99)) {
x[x < quantile(x, limits[1], na.rm = TRUE)] <- quantile(x, limits[1], na.rm = TRUE)
x[x > quantile(x, limits[2], na.rm = TRUE)] <- quantile(x, limits[2], na.rm = TRUE)
x
}
# Apply to new features
selected_data <- selected_data %>%
mutate(across(
all_of(EDA_selected),  # Use all_of() for safety
winsorize
))
# Fixes the random number generator to ensure the same data split every time.
set.seed(123)  # For reproducibility
# Splits the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]
# Option A: Log-transform Price
# Applies the natural logarithm to Price in the training set only (to avoid data leakage).
train_data$log_Price <- log(train_data$Price)
# Option B: Remove extreme values (e.g., top/bottom 1%)
# price_cutoffs <- quantile(train_data$log_Price, c(0.01, 0.99))
# train_clean <- train_data %>%
#   filter(log_Price > price_cutoffs[1] & log_Price < price_cutoffs[2])
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
library(car)
getwd()
install.packages("car")
renv::status()
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/preprocessed/cars_v1.csv", show_col_types = FALSE)
summary(df)
TARGET = 'Price'
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")
EDA_selected = c('Brand_Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)
# Function to winsorize
winsorize <- function(x, limits = c(0.01, 0.99)) {
x[x < quantile(x, limits[1], na.rm = TRUE)] <- quantile(x, limits[1], na.rm = TRUE)
x[x > quantile(x, limits[2], na.rm = TRUE)] <- quantile(x, limits[2], na.rm = TRUE)
x
}
# Apply to new features
selected_data <- selected_data %>%
mutate(across(
all_of(EDA_selected),  # Use all_of() for safety
winsorize
))
# Fixes the random number generator to ensure the same data split every time.
set.seed(123)  # For reproducibility
# Splits the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]
# Option A: Log-transform Price
# Applies the natural logarithm to Price in the training set only (to avoid data leakage).
train_data$log_Price <- log(train_data$Price)
# Option B: Remove extreme values (e.g., top/bottom 1%)
# price_cutoffs <- quantile(train_data$log_Price, c(0.01, 0.99))
# train_clean <- train_data %>%
#   filter(log_Price > price_cutoffs[1] & log_Price < price_cutoffs[2])
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
library(car)
vif(your_lm_model)
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
library(car)
vif(lm_model)
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
library(car)
vif(lm_model)
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
library(car)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/preprocessed/cars_v1.csv", show_col_types = FALSE)
summary(df)
TARGET = 'Price'
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")
EDA_selected = c('Brand_Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)
# Function to winsorize
winsorize <- function(x, limits = c(0.01, 0.99)) {
x[x < quantile(x, limits[1], na.rm = TRUE)] <- quantile(x, limits[1], na.rm = TRUE)
x[x > quantile(x, limits[2], na.rm = TRUE)] <- quantile(x, limits[2], na.rm = TRUE)
x
}
# Apply to new features
selected_data <- selected_data %>%
mutate(across(
all_of(EDA_selected),  # Use all_of() for safety
winsorize
))
# Fixes the random number generator to ensure the same data split every time.
set.seed(123)  # For reproducibility
# Splits the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]
# Option A: Log-transform Price
# Applies the natural logarithm to Price in the training set only (to avoid data leakage).
train_data$log_Price <- log(train_data$Price)
# Option B: Remove extreme values (e.g., top/bottom 1%)
# price_cutoffs <- quantile(train_data$log_Price, c(0.01, 0.99))
# train_clean <- train_data %>%
#   filter(log_Price > price_cutoffs[1] & log_Price < price_cutoffs[2])
# Train model
# Use formula syntax (Price ~ . uses all other columns as predictors)
# Create formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "log_Price")
# Train model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Print model coefficients
summary(lm_model$finalModel)
vif(lm_model$finalModel)
# Predict on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = log(Price), y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# residuals <- residuals(lm_model$finalModel)
# Extract residuals and fitted values
model_data <- data.frame(
Fitted = fitted(lm_model$finalModel),
Residuals = residuals(lm_model$finalModel)
)
# Converting to dataframe for ggplot
# residuals_df <- data.frame(Residuals = residuals)
# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
geom_histogram(
aes(y = after_stat(density)),
bins = 50,
fill = "steelblue",
color = "white",
alpha = 0.8
) +
geom_density(color = "red", linewidth = 1) +
labs(
title = "Distribution of Model Residuals",
x = "Residuals (Actual - Predicted Price)",
y = "Density"
) +
theme_minimal()
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
labs(
title = "Residuals vs. Fitted Values",
subtitle = "Check for homoscedasticity (constant variance)",
x = "Fitted Values (Predicted Price)",
y = "Residuals (Actual - Predicted)"
) +
theme_minimal()
p1
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
stat_qq(color = "steelblue") +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Normal Q-Q Plot",
subtitle = "Check for normality of residuals",
x = "Theoretical Quantiles",
y = "Sample Quantiles"
) +
theme_minimal()
p2
vif(lm_model$finalModel)
