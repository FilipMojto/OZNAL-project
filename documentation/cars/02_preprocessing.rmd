---
title: "EDA for OZNAL project"
author: "Filip Remšík, Filip Mojto"
date: "`r Sys.Date()`" # the date updates automatically when rendered
output:
  pdf_document:
    toc: true
  html_document:
    toc: true # Adds a table of contents (TOC)
    toc_float: true # Makes the TOC float on the side
---

# 02 - Preprocessing

Now we will perform the data preprocessing based on the result from the eda.

## Setup

```{r setup, include=FALSE}
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run

# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)

```

## Libraries

This is a list of libraries we are going to need throughout this document. Must be run before any other block.

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(conflicted)
library(pwr)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")


```

## Dataset

```{r}
paste("Loading dataset from '", getwd(), "'")

df <- read_csv("../../data/raw/australian_vehicle_prices.csv", show_col_types = FALSE)
```

We select only the columns we will need for our solution.

```{r}
colnames(df)[colnames(df) == "Car/Suv"] <- "Car_Suv"

PREDICTORS <- c('Brand', 'Year', 'Model', 
                'Car_Suv', 'UsedOrNew', 
                'Transmission', 'Kilometres', 'Location', 'Engine',     'ColourExtInt', 'FuelType','DriveType','BodyType')
TARGET <- 'Price'

df <- df[, c(PREDICTORS, TARGET)]
df

```

## Cylinders

Extract actually replaces the original column with new ones based on regex match

```{r}
df <- df %>%
  extract(
    Engine,                 # The source column containing engine info
    into = c("Cylinders", "Engine_L"),  # New columns to create
    regex = "(\\d+) cyl, (\\d+\\.?\\d*) L",  # Pattern to match
    convert = TRUE          # Automatically convert to appropriate data types
  )

df
```

## Missing values

After reviewing the data, we discovered that some records appeared empty but contained a character, so we corrected them.

```{r}
df[df == "-" | df == "-/-"] <- NA
```

```{r}
missing_summary <- data.frame(
  Column = names(df),
  Missing_Count = colSums(is.na(df)))

missing_summary
```

## Deleting rows

Since there aren't many missing values and imputing them could degrade the data quality, we decided to remove them based on a sufficient amount of data and the potential deterioration if the values were replaced with other ones.

```{r}
rows_before <- nrow(df)
print(paste("Rows before removing NA:", rows_before))

# Step 2: Remove rows with any NA values
df <- na.omit(df)

# Step 3: Count rows after removing NA
rows_after <- nrow(df)
print(paste("Rows after removing NA:", rows_after))
```

To determine whether our sample remained sufficient after data removal, we performed a power analysis, which yielded a positive result, indicating that the sample is still adequate.

```{r}
predictors <- 13 
observations <- rows_after  
effect_size <- 0.15 

power_test <- pwr.f2.test(u = predictors,
                          v = observations - predictors - 1,
                          f2 = effect_size,
                          sig.level = 0.05)

print(power_test)
```

## Encoding

Because data contain a lot of categorical attributes that are relevant to our goal, we've created the following function. This function performs so-called **Target Encoding** which is different from standard one-hot encoding in that that is encodes the categories based on how strong impact the predictor has on the target. Higher average price for the particular predictors means higher assigned number.

```{r}
# target.encode <- function(df, target, col) {
#   # Convert column name to symbol for tidy evaluation
#   col_sym <- sym(col)
#   encoded_col_name <- paste0(col, "_encoded")
#   
#   # Step 1: Calculate mean target per group
#   avg_target <- df %>%
#     group_by(!!col_sym) %>%
#     summarise(mean_target = mean(.data[[target]], na.rm = TRUE), .groups = "drop") %>%
#     arrange(mean_target)
# 
#   # Step 2: Assign ranks
#   avg_target <- avg_target %>%
#     mutate(!!encoded_col_name := as.numeric(factor(mean_target, levels = unique(mean_target))) - 1)
# 
#   # Step 3: Join encoded column back to original dataframe
#   df <- df %>%
#     left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)
# 
#   return(df)
# }

target.encode <- function(train_df, test_df, target, col) {
  col_sym <- sym(col)
  encoded_col_name <- paste0(col, "_encoded")

  # Step 1: Calculate mean target per group (train set only)
  avg_target <- train_df %>%
    group_by(!!col_sym) %>%
    summarise(mean_target = mean(.data[[target]], na.rm = TRUE), .groups = "drop") %>%
    arrange(mean_target)

  # Step 2: Assign ranks
  avg_target <- avg_target %>%
    mutate(!!encoded_col_name := as.numeric(factor(mean_target, levels = unique(mean_target))) - 1)

  # Step 3: Join encoded column to both train and test
  train_df <- train_df %>%
    left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)

  test_df <- test_df %>%
    left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)

  # Optionally fill NAs in test set (unseen categories) with a default, e.g. median or -1
  test_df[[encoded_col_name]][is.na(test_df[[encoded_col_name]])] <- -1

  return(list(train = train_df, test = test_df))
}
```

```{r}
COLS_TO_ENCODE <- c('Brand', 'Model', 'Car_Suv', 'UsedOrNew', 'Transmission', 'DriveType', 'FuelType', 'ColourExtInt', 'Location', 'BodyType')

set.seed(123)  # For reproducibility

train_index <- createDataPartition(df$Price, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data  <- df[-train_index, ]

# 
# df <- reduce(COLS_TO_ENCODE, ~ target.encode(df = .x, target = TARGET, col = .y), .init = df)
# 
# df

for (col in COLS_TO_ENCODE) {
  encoded <- target.encode(train_data, test_data, target = "Price", col = col)
  train_data <- encoded$train
  test_data  <- encoded$test
}

df <- rbind(train_data, test_data)
df
```

## Change Kilometers to numerical

```{r}
df <- df %>%
  mutate(Kilometres_num = as.numeric(gsub("[^0-9]", "", Kilometres)))
numeric_cols <- df[, sapply(df, is.numeric)]

```

## Year -\> Age

Age is time-based feature and thus it introduces inflation. Is is therefore wise to convert it into age using the following formula:

*age = current - manufacturing_year*

```{r}

current_year <- as.numeric(format(Sys.Date(), "%Y"))
df$age <- current_year - df$Year
```

## Remowing columns, that are no longer need

```{r}
df <- df %>% select(-c('Brand', 'Model', 'Car_Suv', 'UsedOrNew', 'Transmission','Year','Kilometres','Location','Engine_L','ColourExtInt','FuelType','DriveType','BodyType'))
```

## Handling outliers

```{r}

num_cols <- df[, sapply(df, is.numeric)]

# Loop through each numeric column
for (colname in names(num_cols)) {
  boxplot(num_cols[[colname]],
          main = paste("Boxplot of", colname),
          ylab = colname)
}
```

## Apply Log scale on Price

Our target variable, Price, has a skewed distribution; therefore, we decided to use a log scale.

```{r}
df <- df %>% mutate(Price_log = log10(Price + 1))

```

### Outliers

Since we found out during EDA that the data contains outliers, we decided to remove them using a custom IQR range based on the 5th and 95th percentile.

```{r}
detect_outliers_iqr <- function(df, remove = FALSE) {
  num_cols <- df[, sapply(df, is.numeric), drop = FALSE]
  
  outlier_flags <- matrix(FALSE, nrow = nrow(df), ncol = ncol(num_cols))
  
  for (i in seq_along(num_cols)) {
    x <- num_cols[[i]]
    Q1 <- quantile(x, 0.05, na.rm = TRUE)
    Q3 <- quantile(x, 0.95, na.rm = TRUE)
    IQR_val <- IQR(x, na.rm = TRUE)
    
    lower <- Q1 - 1.5 * IQR_val
    upper <- Q3 + 1.5 * IQR_val
    
    outlier_flags[, i] <- x < lower | x > upper
  }
  
  if (remove) {
    df <- df[!apply(outlier_flags, 1, any), ]
  }
  
  return(df)
}


```

```{r}
df<- detect_outliers_iqr(df, remove = TRUE)
```

## Save data for training

```{r}
write.csv(df, file = "../../data/preprocessed/cars_v2.csv", row.names = FALSE)  # Avoid row numbers
```
