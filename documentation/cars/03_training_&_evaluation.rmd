---
get---
title: "EDA for OZNAL project"
author: "Filip Remšík, Filip Mojto"
date: "`r Sys.Date()`" # the date updates automatically when rendered
output:
  pdf_document:
    toc: true
  html_document:
    toc: true # Adds a table of contents (TOC)
    toc_float: true # Makes the TOC float on the side
---

```{r setup, include=FALSE}
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run

# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)

```

## Libraries

```{r}

library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
library(car)


conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")

```

## Dataset

```{r}

paste("Loading dataset from '", getwd(), "'")

df <- read_csv("../../data/preprocessed/cars_v2.csv", show_col_types = FALSE)
summary(df)
```

## Target & Predictors

```{r}

TARGET <- c('Price', 'Price_log')
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")


EDA_selected <- c('Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
  
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
# selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)

```

## Linear Regression

EDA showed roughly linear relationships between predictors and log target. Thus, we are going to try to fit Linear Regression on this problem.

### Train/Test Split

Now we can final train the model. First we are going to follow the best practices for machine learning workflow by splitting the data into training and testing dataset. By doing so, we are going to preserve the data integrity. This is because we only apply cross validation on the training set to avoid data leakage and the testing set remains unseen.

We are going to apply 80:20 split. Generally, the fewer observations are present in data the greater the portion of the testing subset should be.

```{r}

# Fixing the random number generator to ensure the same data split every time.
set.seed(123) 

# Splitting the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]

```

### Function Fitting & Cross Validation

Our dataset (consisting of 16000 of car listings) is **large enough** to split into 5 folds while still maintaining sufficient training examples in each fold. It's also **computationally efficient** compared to higher *k* or repeated CV. **LOOCV** technique works for very small datasets (\<100 rows), where maximizing training data is crucial. **Stratified k-Fold Cross-Validation** is best suited for classification problems with imbalanced classes.

We're training a **linear model**, which is not prone to over-fitting. Hence, 5-fold CV provides a **good trade-off** between training on sufficient data and testing on unseen data without being overly expensive.

```{r}

# Creating formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "Price_log")

# Training model
lm_model <- train(
  model_formula,
  data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)

# Printing model coefficients
summary(lm_model$finalModel)
```

-   The model shows an **R-squared of 0.8508**, meaning **approximately 85.1% of the variance in `log_Price` is explained** by the included predictors. This indicates a strong model fit.
-   The **residual standard error is 0.2491**, which means that about **68% of predictions fall within ±0.249 log-units** of the actual log-price.
-   Converting this error back to the original price scale:

```         
-    `exp(0.249) ≈ 1.28` → predictions may overestimate true price by up to **28%**.

-    `exp(-0.249) ≈ 0.78` → predictions may underestimate true price by up to **22%**.
```

-   The **adjusted R-squared is nearly identical to the R-squared (0.8507)**, indicating that all included predictors are contributing meaningfully and that **overfitting is unlikely**.

-   The **F-statistic is extremely high (6547)** with a **p-value \< 2.2e-16**, showing that the model significantly improves upon the null model.

-   **All coefficients are highly statistically significant (p \< 0.001)**, supporting their relevance in predicting `log_Price`.

### Multicollinearity

```{r}

vif(lm_model$finalModel)
```

**Variance Inflation Factors (VIFs)** for all predictors are below 3, with the highest being:

-   age: 2.83

-   Kilometres_num: 2.68

    These values indicate **no concerning multicollinearity** among predictors, even though age and kilometres may be correlated. Their VIFs are well below the common threshold of 5.

### Predicted vs. Actual - Log Scale

Now let's visualize the predicted vs. actual values. This time we are going to make the model predict the testing subset. We also want to compare the values that were scaled using log10 and those which were not.

```{r}

# Predicting on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)

# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- 10 ^ test_data$log_Price_pred

# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = Price_log, y = log_Price_pred)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_abline(slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs. Actual Prices (Log Scale)",
       x = "Actual log(Price)", y = "Predicted log(Price)") +
  theme_minimal()

# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
  geom_point(alpha = 0.4, color = "darkgreen") +
  geom_abline(slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs. Actual Prices (Original Scale)",
       x = "Actual Price", y = "Predicted Price") +
  scale_x_continuous(labels = scales::dollar) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal()

```

### Residuals

Interpreting the **residuals histogram** helps us assess whether our linear model's assumptions are reasonably met. If the histogram is symmetric and centered around 0, that's a good sign — it means our model doesn’t systematically over- or under-predict.

```{r}

# Extracting residuals and fitted values
model_data <- data.frame(
  Fitted = fitted(lm_model$finalModel),
  Residuals = residuals(lm_model$finalModel)
)

# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    bins = 50,
    fill = "steelblue",
    color = "white",
    alpha = 0.8
  ) +
  geom_density(color = "red", linewidth = 1) + 
  labs(
    title = "Distribution of Model Residuals",
    x = "Residuals (Actual - Predicted Price)",
    y = "Density"
  ) +
  theme_minimal()

```

From the distribution above we can say that our model doesn't systematically overpredict or underpredict (skewness). Also the spread is not high which implies low prediction error. The distribution is normal which supports model's inference.

#### Homoscedasticity

Linear and polynomial regression require homoscedasticity of predictors. This means they are scattered around 0 without any clear patterns. We are going to check that out by using Scatterplot and QQPlot.

```{r}

# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
  labs(
    title = "Residuals vs. Fitted Values",
    subtitle = "Check for homoscedasticity (constant variance)",
    x = "Fitted Values (Predicted Price)",
    y = "Residuals (Actual - Predicted)"
  ) +
  theme_minimal()

p1

```

#### QQPlot

```{r}

# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(
    title = "Normal Q-Q Plot",
    subtitle = "Check for normality of residuals",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()

p2
```

From the plots we can tell that residuals are scattered quite normally around zero. Even though loess can catch non-linear relationships, the smooth line shows almost perfect linear match with the horizontal line. From the QQPlot we can see that they almost perfectly follow the line, though there are deviated values (tails).

## Polynomial Regression

Based on EDA we decided to add some predictors to power of 2.

```{r}
train_data$Kilometres_num2 <- train_data$Kilometres_num^2
train_data$age2 <- train_data$age^2
train_data$Cylinders2 <- train_data$Cylinders^2
```

```{r}

EDA_selected = c('Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num2', 'Cylinders2', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded','age2')


model_formula_poly <- reformulate(EDA_selected, response = "Price_log")

lm_poly_model <- train(
  model_formula_poly,
  data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)

# Viewing the summary
summary(lm_poly_model$finalModel)

```

R-square error represents % of variance in log_Price explained by our model (0.82 = 82%)

### Predicted vs. Actual - Log Scale

```{r}
# Predicting on test data
test_data$Kilometres_num2 <- test_data$Kilometres_num^2
test_data$age2 <- test_data$age^2
test_data$Cylinders2 <- test_data$Cylinders^2
test_data$log_Price_pred <- predict(lm_poly_model, newdata = test_data)

# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- 10 ^ test_data$log_Price_pred

# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = log(Price_log), y = log_Price_pred)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_abline(slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs. Actual Prices (Log Scale)",
       x = "Actual log(Price)", y = "Predicted log(Price)") +
  theme_minimal()

# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
  geom_point(alpha = 0.4, color = "darkgreen") +
  geom_abline(slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs. Actual Prices (Original Scale)",
       x = "Actual Price", y = "Predicted Price") +
  scale_x_continuous(labels = scales::dollar) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal()

```

### Residuals

```{r}
# Extracting only residuals and fitted values
model_data <- data.frame(
  Fitted = fitted(lm_model$finalModel),
  Residuals = residuals(lm_model$finalModel)
)

# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
  geom_histogram(
    aes(y = after_stat(density)), 
    bins = 50,
    fill = "steelblue",
    color = "white",
    alpha = 0.8
  ) +
  geom_density(color = "red", linewidth = 1) + 
  labs(
    title = "Distribution of Model Residuals",
    x = "Residuals (Actual - Predicted Price)",
    y = "Density"
  ) +
  theme_minimal()

```

### Homoscedacity

```{r}
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
  labs(
    title = "Residuals vs. Fitted Values",
    subtitle = "Check for homoscedasticity (constant variance)",
    x = "Fitted Values (Predicted Price)",
    y = "Residuals (Actual - Predicted)"
  ) +
  theme_minimal()

p1
```

### QQ Plot

```{r}
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(
    title = "Normal Q-Q Plot",
    subtitle = "Check for normality of residuals",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()

p2
```

## Conclusion

In this document, we trained and compared Linear and Polynomial Regression models. We found out that linear regression was getting better results mainly because of linearity present in the data. We split the dataset into training and testing subsets. During training, we performed k-fold cross-validation. Finally we tested the model on the test subset and visualized the results. We plotted predicted vs. actual values, residual plot, homoscedasticity plot and QQ Plot.
