geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Predicting on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = Price_log, y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
setwd("~/DataAnalysisProjects/OZNAL-project/shiny_app/app/renv")
getwd()
renv::status()
install.packages("car")
getwd()
renv::load()
renv::status()
renv::snapshot()
renv::status()
install.packages("car")
renv::status()
renv::snapshot()
renv::status()
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
library(scales)  # for comma()
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/raw/australian_vehicle_prices.csv", show_col_types = FALSE)
summary(df)
colnames(df)[colnames(df) == "Car/Suv"] <- "Car_Suv"
df$Brand_Model <- paste(df$Brand, df$Model)
PREDICTORS <- c('Brand_encoded', 'age', 'Model_encoded',
'Car_Suv_encoded', 'UsedOrNew_encoded',
'Transmission_encoded', 'Kilometres_num',
'Cylinders', 'Engine_L', 'DriveType_encoded',
'FuelType_encoded', 'FuelConsumption_num',
'ColourExtInt_encoded', 'Location_encoded',
'BodyType_encoded', 'Doors_num', 'Seats_num', 'Brand_Model_encoded')
TARGET <- 'Price'
df
colMeans(is.na(df))
# just for EDA purposes, they will be handled properly later in preprocessing
df <- df %>%
filter(complete.cases(.))
target.encode <- function(train_df, test_df, target, col) {
col_sym <- sym(col)
encoded_col_name <- paste0(col, "_encoded")
# Step 1: Calculate mean target per group (train set only)
avg_target <- train_df %>%
group_by(!!col_sym) %>%
summarise(mean_target = mean(.data[[target]], na.rm = TRUE), .groups = "drop") %>%
arrange(mean_target)
# Step 2: Assign ranks
avg_target <- avg_target %>%
mutate(!!encoded_col_name := as.numeric(factor(mean_target, levels = unique(mean_target))) - 1)
# Step 3: Join encoded column to both train and test
train_df <- train_df %>%
left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)
test_df <- test_df %>%
left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)
# Optionally fill NAs in test set (unseen categories) with a default, e.g. median or -1
test_df[[encoded_col_name]][is.na(test_df[[encoded_col_name]])] <- -1
return(list(train = train_df, test = test_df))
}
COLS_TO_ENCODE <- c('Brand', 'Model', 'Car_Suv', 'UsedOrNew', 'Transmission', 'DriveType', 'FuelType', 'ColourExtInt', 'Location', 'BodyType', 'Brand_Model')
set.seed(123)
train_index <- createDataPartition(df$Price, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data  <- df[-train_index, ]
# encoding the training and testing sets separately
for (col in COLS_TO_ENCODE) {
encoded <- target.encode(train_data, test_data, target = "Price", col = col)
train_data <- encoded$train
test_data  <- encoded$test
}
# joining the datasets into one
df <- rbind(train_data, test_data)
df
current_year <- as.numeric(format(Sys.Date(), "%Y"))
df$age <- current_year - df$Year
# extract actually replaces the original column with new ones based on regex match
df <- df %>%
extract(
Engine,                 # The source column containing engine info
into = c("Cylinders", "Engine_L"),  # New columns to create
regex = "(\\d+) cyl, (\\d+\\.?\\d*) L",  # Pattern to match
convert = TRUE          # Automatically convert to appropriate data types
)
#some new missing values are introduced, we remove them
df <- df %>%
filter(!is.na(Cylinders), !is.na(Engine_L))
df
df <- df %>%
mutate(
FuelConsumption_num = as.numeric(str_extract(FuelConsumption, "\\d+\\.?\\d*"))
)
df
df$Doors_num <- as.numeric(gsub("[^0-9]", "", df$Doors))
df$Seats_num <- as.numeric(gsub("[^0-9]", "", df$Seats))
df$Kilometres_num <- as.numeric(gsub("[^0-9]", "", df$Kilometres))
#some new missing values are introduced, we remove them
df <- df %>%
filter(!is.na(Kilometres_num), !is.na(Price))
df
summary(df)
show.correlation.plot <- function(df, target, col){
p <- ggplot(df, aes(x = .data[[col]], y = .data[[target]])) +
geom_point(alpha = 0.5, color = "steelblue") +
geom_smooth(method = "lm", color = "red") +  # Linear trend line
labs(title = paste0(target, " vs. ", col), x = col, y = target) +
theme_minimal()
return(p)
}
plots <- map(PREDICTORS, ~show.correlation.plot(df = df, target = TARGET, col = .x))
walk(plots, print)
show.corrplot <- function(matrix){
p <- corrplot(
matrix,
method = 'color',
type = 'lower',
tl.cex = 0.6,        # much smaller axis text
cl.cex = 0.6,        # smaller colorbar text
addCoef.col = "black",
number.cex = 0.5,    # smaller correlation coefficients
tl.srt = 45
)
print(p)
}
cor_data <- df %>% select(all_of(PREDICTORS), all_of(TARGET))
cor_matrix <- cor(cor_data, use = "complete.obs")
show.corrplot(cor_matrix)
show.boxplot <- function(data, cols, target, bins = 5) {
# binning the data
data <- data %>%
mutate(target_binned = cut(.data[[target]], breaks = bins, include.lowest = TRUE))
plots <- map(cols, ~ggplot(
data,
aes(x = target_binned, y = .data[[.x]])) +
geom_boxplot(aes(group = target_binned)) +
labs(x = paste0(target, " (binned)"), y = .x) +
theme_minimal() +
# we wrap long bin labels by adding newline
scale_x_discrete(labels = function(x) gsub(",", "\n", x))
)
walk(plots, print)
}
show.boxplot(data = df, cols = PREDICTORS, target = TARGET, bins = 10)
# Histogram with log scale
ggplot(df, aes(x = Price)) +
geom_histogram(fill = "skyblue", color = "black", bins = 30) +
labs(
title = "Distribution of Vehicle Prices (Log Scale)",
x = "Price (Log10 Scale)",
y = "Count"
) +
theme_minimal()
# Histogram with log scale
ggplot(df, aes(x = Price)) +
geom_histogram(fill = "skyblue", color = "black", bins = 30) +
scale_x_log10(labels = scales::dollar) +  # Log scale for skewed data
labs(
title = "Distribution of Vehicle Prices (Log Scale)",
x = "Price (Log10 Scale)",
y = "Count"
) +
theme_minimal()
selected_df <- df %>% select(all_of(PREDICTORS), all_of(TARGET))
write.csv(selected_df, file = "../../data/preprocessed/cars_v1.csv", row.names = FALSE)  # Avoid row numbers
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(conflicted)
library(pwr)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/raw/australian_vehicle_prices.csv", show_col_types = FALSE)
colnames(df)[colnames(df) == "Car/Suv"] <- "Car_Suv"
PREDICTORS <- c('Brand', 'Year', 'Model',
'Car_Suv', 'UsedOrNew',
'Transmission', 'Kilometres', 'Location', 'Engine',     'ColourExtInt', 'FuelType','DriveType','BodyType')
TARGET <- 'Price'
df <- df[, c(PREDICTORS, TARGET)]
df
df <- df %>%
extract(
Engine,                 # The source column containing engine info
into = c("Cylinders", "Engine_L"),  # New columns to create
regex = "(\\d+) cyl, (\\d+\\.?\\d*) L",  # Pattern to match
convert = TRUE          # Automatically convert to appropriate data types
)
df
df[df == "-" | df == "-/-"] <- NA
missing_summary <- data.frame(
Column = names(df),
Missing_Count = colSums(is.na(df)))
missing_summary
rows_before <- nrow(df)
print(paste("Rows before removing NA:", rows_before))
# Step 2: Remove rows with any NA values
df <- na.omit(df)
# Step 3: Count rows after removing NA
rows_after <- nrow(df)
print(paste("Rows after removing NA:", rows_after))
predictors <- 13
observations <- rows_after
effect_size <- 0.15
power_test <- pwr.f2.test(u = predictors,
v = observations - predictors - 1,
f2 = effect_size,
sig.level = 0.05)
print(power_test)
target.encode <- function(train_df, test_df, target, col) {
col_sym <- sym(col)
encoded_col_name <- paste0(col, "_encoded")
# Step 1: Calculate mean target per group (train set only)
avg_target <- train_df %>%
group_by(!!col_sym) %>%
summarise(mean_target = mean(.data[[target]], na.rm = TRUE), .groups = "drop") %>%
arrange(mean_target)
# Step 2: Assign ranks
avg_target <- avg_target %>%
mutate(!!encoded_col_name := as.numeric(factor(mean_target, levels = unique(mean_target))) - 1)
# Step 3: Join encoded column to both train and test
train_df <- train_df %>%
left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)
test_df <- test_df %>%
left_join(avg_target %>% select(!!col_sym, !!sym(encoded_col_name)), by = col)
# Optionally fill NAs in test set (unseen categories) with a default, e.g. median or -1
test_df[[encoded_col_name]][is.na(test_df[[encoded_col_name]])] <- -1
return(list(train = train_df, test = test_df))
}
COLS_TO_ENCODE <- c('Brand', 'Model', 'Car_Suv', 'UsedOrNew', 'Transmission', 'DriveType', 'FuelType', 'ColourExtInt', 'Location', 'BodyType')
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$Price, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data  <- df[-train_index, ]
for (col in COLS_TO_ENCODE) {
encoded <- target.encode(train_data, test_data, target = "Price", col = col)
train_data <- encoded$train
test_data  <- encoded$test
}
df <- rbind(train_data, test_data)
df
df <- df %>%
mutate(Kilometres_num = as.numeric(gsub("[^0-9]", "", Kilometres)))
numeric_cols <- df[, sapply(df, is.numeric)]
current_year <- as.numeric(format(Sys.Date(), "%Y"))
df$age <- current_year - df$Year
df <- df %>% select(-c('Brand', 'Model', 'Car_Suv', 'UsedOrNew', 'Transmission','Year','Kilometres','Location','Engine_L','ColourExtInt','FuelType','DriveType','BodyType'))
num_cols <- df[, sapply(df, is.numeric)]
# Loop through each numeric column
for (colname in names(num_cols)) {
boxplot(num_cols[[colname]],
main = paste("Boxplot of", colname),
ylab = colname)
}
df <- df %>% mutate(Price_log = log10(Price + 1))
detect_outliers_iqr <- function(df, remove = FALSE) {
num_cols <- df[, sapply(df, is.numeric), drop = FALSE]
outlier_flags <- matrix(FALSE, nrow = nrow(df), ncol = ncol(num_cols))
for (i in seq_along(num_cols)) {
x <- num_cols[[i]]
Q1 <- quantile(x, 0.05, na.rm = TRUE)
Q3 <- quantile(x, 0.95, na.rm = TRUE)
IQR_val <- IQR(x, na.rm = TRUE)
lower <- Q1 - 1.5 * IQR_val
upper <- Q3 + 1.5 * IQR_val
outlier_flags[, i] <- x < lower | x > upper
}
if (remove) {
df <- df[!apply(outlier_flags, 1, any), ]
}
return(df)
}
df<- detect_outliers_iqr(df, remove = TRUE)
write.csv(df, file = "../../data/preprocessed/cars_v2.csv", row.names = FALSE)  # Avoid row numbers
# A code chunk labeled setup.
# this chunk will not appear in the final document (no code, no output shown), but it will run
# Sets global options for all subsequent code chunks.
#echo = TRUE means R code will be displayed in the output (HTML/PDF).
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(conflicted)
library(corrplot)
library(purrr)
library(caret)
library(nnet)
library(pROC)
library(car)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("select", "dplyr")
paste("Loading dataset from '", getwd(), "'")
df <- read_csv("../../data/preprocessed/cars_v2.csv", show_col_types = FALSE)
summary(df)
TARGET <- c('Price', 'Price_log')
# Create a new feature combining Brand + Model (e.g., "Toyota_Corolla")
EDA_selected <- c('Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num', 'Cylinders', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded', 'UsedOrNew_encoded', 'age')
selected_data <- df %>% select(all_of(EDA_selected), all_of(TARGET))
# selected_data <- selected_data %>% filter(complete.cases(.))
summary(selected_data)
# Fixing the random number generator to ensure the same data split every time.
set.seed(123)
# Splitting the data into 80% training and 20% testing, preserving the distribution of Price
train_index <- createDataPartition(selected_data$Price, p = 0.8, list = FALSE)
train_data <- selected_data[train_index, ]
test_data  <- selected_data[-train_index, ]
# Creating formula dynamically
# log_Price ~ Brand_Encoded + Model_encoded + ...
model_formula <- reformulate(EDA_selected, response = "Price_log")
# Training model
lm_model <- train(
model_formula,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Printing model coefficients
summary(lm_model$finalModel)
vif(lm_model$finalModel)
# Predicting on test data
test_data$log_Price_pred <- predict(lm_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = Price_log, y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Extracting residuals and fitted values
model_data <- data.frame(
Fitted = fitted(lm_model$finalModel),
Residuals = residuals(lm_model$finalModel)
)
# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
geom_histogram(
aes(y = after_stat(density)),
bins = 50,
fill = "steelblue",
color = "white",
alpha = 0.8
) +
geom_density(color = "red", linewidth = 1) +
labs(
title = "Distribution of Model Residuals",
x = "Residuals (Actual - Predicted Price)",
y = "Density"
) +
theme_minimal()
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
labs(
title = "Residuals vs. Fitted Values",
subtitle = "Check for homoscedasticity (constant variance)",
x = "Fitted Values (Predicted Price)",
y = "Residuals (Actual - Predicted)"
) +
theme_minimal()
p1
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
stat_qq(color = "steelblue") +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Normal Q-Q Plot",
subtitle = "Check for normality of residuals",
x = "Theoretical Quantiles",
y = "Sample Quantiles"
) +
theme_minimal()
p2
train_data$Kilometres_num2 <- train_data$Kilometres_num^2
train_data$age2 <- train_data$age^2
train_data$Cylinders2 <- train_data$Cylinders^2
EDA_selected = c('Model_encoded', 'Location_encoded', 'Car_Suv_encoded', 'Kilometres_num2', 'Cylinders2', 'ColourExtInt_encoded', 'FuelType_encoded','DriveType_encoded','age2')
model_formula_poly <- reformulate(EDA_selected, response = "Price_log")
lm_poly_model <- train(
model_formula_poly,
data = train_data,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Viewing the summary
summary(lm_poly_model$finalModel)
# Predicting on test data
test_data$Kilometres_num2 <- test_data$Kilometres_num^2
test_data$age2 <- test_data$age^2
test_data$Cylinders2 <- test_data$Cylinders^2
test_data$log_Price_pred <- predict(lm_poly_model, newdata = test_data)
# To revert to the unscaled values, we calculate the exponent of the logged values
test_data$Price_pred <- exp(test_data$log_Price_pred)
# --- 1. Plot: Predicted vs. Actual (log scale) ---
ggplot(test_data, aes(x = log(Price_log), y = log_Price_pred)) +
geom_point(alpha = 0.4, color = "blue") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Log Scale)",
x = "Actual log(Price)", y = "Predicted log(Price)") +
theme_minimal()
# --- 2. Plot: Predicted vs. Actual (original price scale) ---
ggplot(test_data, aes(x = Price, y = Price_pred)) +
geom_point(alpha = 0.4, color = "darkgreen") +
geom_abline(slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual Prices (Original Scale)",
x = "Actual Price", y = "Predicted Price") +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Extracting only residuals and fitted values
model_data <- data.frame(
Fitted = fitted(lm_model$finalModel),
Residuals = residuals(lm_model$finalModel)
)
# Creating histogram with density overlay with density curve
ggplot(model_data, aes(x = Residuals)) +
geom_histogram(
aes(y = after_stat(density)),
bins = 50,
fill = "steelblue",
color = "white",
alpha = 0.8
) +
geom_density(color = "red", linewidth = 1) +
labs(
title = "Distribution of Model Residuals",
x = "Residuals (Actual - Predicted Price)",
y = "Density"
) +
theme_minimal()
# Residuals vs. Fitted Plot
p1 <- ggplot(model_data, aes(x = Fitted, y = Residuals)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
geom_smooth(method = "loess", color = "darkgreen", se = FALSE) +
labs(
title = "Residuals vs. Fitted Values",
subtitle = "Check for homoscedasticity (constant variance)",
x = "Fitted Values (Predicted Price)",
y = "Residuals (Actual - Predicted)"
) +
theme_minimal()
p1
# QQ-Plot
p2 <- ggplot(model_data, aes(sample = Residuals)) +
stat_qq(color = "steelblue") +
stat_qq_line(color = "red", linetype = "dashed") +
labs(
title = "Normal Q-Q Plot",
subtitle = "Check for normality of residuals",
x = "Theoretical Quantiles",
y = "Sample Quantiles"
) +
theme_minimal()
p2
